 \begin{table}
   \caption{SVMでの次元数30の170文に対する正答率（\%）}
   \label{table:svm_30_170}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_1.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数40の170文に対する正答率（\%）}
   \label{table:svm_40_170}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_2.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数50の170文に対する正答率（\%）}
   \label{table:svm_50_170}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_3.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数100の170文に対する正答率（\%）}
   \label{table:svm_100_170}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_4.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数200の170文に対する正答率（\%）}
   \label{table:svm_200_170}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_5.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数30の48文に対する正答率（\%）}
   \label{table:svm_30_48}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_6.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数40の48文に対する正答率（\%）}
   \label{table:svm_40_48}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_7.png}
   \end{center}
 \end{table}

 
  \begin{table}
   \caption{SVMでの次元数50の48文に対する正答率（\%）}
   \label{table:svm_50_48}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_8.png}
   \end{center}
 \end{table}

 
  \begin{table}
   \caption{SVMでの次元数100の48文に対する正答率（\%）}
   \label{table:svm_100_48}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_9.png}
   \end{center}
 \end{table}

 
  \begin{table}
   \caption{SVMでの次元数200の48文に対する正答率（\%）}
   \label{table:svm_200_48}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_10.png}
   \end{center}
 \end{table}

  \begin{table}
   \caption{ニューラルネットワークでの次元数30の170文に対する正答率（\%）}
   \label{table:nn_30_170}
   \begin{center}
     \includegraphics[width=\linewidth]{nn_30_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{ニューラルネットワークでの次元数40の170文に対する正答率（\%）}
   \label{table:nn_40_170}
   \begin{center}
     \includegraphics[width=\linewidth]{nn_40_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{ニューラルネットワークでの次元数50の170文に対する正答率（\%）}
   \label{table:nn_50_170}
   \begin{center}
     \includegraphics[width=\linewidth]{nn_50_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{ニューラルネットワークでの次元数100の170文に対する正答率（\%）}
   \label{table:nn_100_170}
   \begin{center}
     \includegraphics[width=\linewidth]{nn_100_170.png}
   \end{center}
 \end{table}
 
 

 \begin{table}
   \caption{ニューラルネットワークでの次元数200の170文に対する正答率（\%）}
   \label{table:nn_200_170}
   \begin{center}
     \includegraphics[width=\linewidth]{nn_200_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{170文に対する分類手法の比較}
   \label{table:170_compare}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_16.png}
   \end{center}
 \end{table}
 

 \begin{table}
   \caption{48文に対する分類手法の比較}
   \label{table:48_compare}
   \begin{center}
     \includegraphics[width=\linewidth]{hayashida4_17.png}
   \end{center}
 \end{table}
本章では，本研究における分類手法の分類精度を高めるためのパラメータ調整に関する実験，会話の流れの可視化システムにおける分類手法との比較を行う．さらに，実験結果に対する考察を行い，本研究における分類手法の問題点を述べる．


\section{実験概要}

本研究ではSVMによる機械学習を行うために，オープンソースの機械学習ライブラリであるscikit-learnを使用する．さらにニューラルネットワークによる学習を行うために，Googleが開発しオープンソースとして公開されているTensorflowを使用する．共に使用するプログラム言語はPythonである．

次に本研究の実験で使用したテキストデータについて述べる．word2vecの学習に用いたコーパスは，Yahoo!知恵袋の「恋愛相談」，「友人関係の悩み」，「家族関係の悩み」，「職場の悩み」４カテゴリの，各カテゴリ6,000件ずつ，質問24,000件，質問に対するベストアンサー24,000件の計48,000件（単語数6,298,390，語彙数18,100，サイズ37.4MB）である．また，テキストデータの1件とは，投稿者1人の投稿文章である．本研究における分類対象はクライエントの発言内容であり，相談することを目的としてYahoo!知恵袋に投稿した投稿者の質問文が内容的に比較的類似しているため，教師データに関して，質問文のみを用いることとした．

機械学習の教師データに用いたテキストデータは， Yahoo!知恵袋の，「家族関係の悩み」，「友人関係の悩み」，「職場の悩み」カテゴリの質問文を1文毎に区切った，各カテゴリ6,000文ずつ，計18,000文である．機械学習のテストデータに用いたテキストデータは，クライエントの発言のうち，熟練カウンセラーの手動修正後「愛」「交友」「仕事」いずれかのカテゴリに分類されていた170文である．


次に，質問文を1文毎に区切り，3.3節で述べた手順に従って，1文毎に文ベクトルを作成する．ここで1文とは，句点やクエスチョンマークで区切られた単位のことである．「家族関係の悩み」カテゴリから取得した質問文1文毎の文ベクトルに「愛」のラベル，「友人関係の悩み」カテゴリの質問文1文毎の文ベクトルに「交友」ラベル，「職場の悩み」カテゴリの質問文1文毎の文ベクトルに「仕事」ラベルをそれぞれ付けて，教師データとする．


テストデータに関して，クライエントの発言1文毎のうち，ユーザーの手動修正後「愛」「交友」「仕事」いずれかのカテゴリに分類されていた170文をテストデータに用いる．クライエントの発言170文に対して3.3節で述べた手順に従い文ベクトルを算出し，テストデータとした．第1章でも述べたように，会話の流れの可視化システムにおけるクライエントの発言の分類結果について，熟練カウンセラーが確認を行い，誤った分類箇所を手動修正している．その手動修正後の分類カテゴリをテストデータの正解カテゴリとする．

しかし，クライエントの発言1文毎の170文の中には，カウンセラーからの質問に対する単なる返事などといった，その1文だけをカテゴリ分類することが難しいと考えられる文も含まれている．そこで，
\begin{enumerate}
\item 「そのことで夜眠れなくて・・・」のように，「そのこと」が何のことかを把握するために，前の発言文に遡らなければならない文
\item 「不安です．」のように，カウンセラーからの質問に対する返事などの短い文
\end{enumerate}
といった文を170文野中から除外して，残った48文に対する実験も同様に行う．

本実験では，分類精度を評価する指標として正答率を用いる．正答率とは，全てのテストデータに対して，正しいカテゴリを出力した割合であり，テストデータのうち正解カテゴリと同じ出力をした数をT，正解カテゴリと異なる出力した数をF，正答率(\%)をAccuracyとすると，
\begin{equation}
  Accuracy=\frac{T}{T+F}×100
\end{equation}
と表すことができる．
これらのテキストデータ，評価指標を用いて以下に述べる実験を行う．

\section{実験結果}

\subsection{実験内容}

はじめに，SVMとニューラルネットワークについて，本研究における分類手法の精度を高めるために，パラメータを調整する実験をそれぞれ行う．3.4節で述べたように，SVMではカーネル関数とパラメータCおよび$\gamma$の選択によって分離超平面がそれぞれ異なり分類精度も大きく異なる．ニューラルネットワークでも同様に扱うデータにより適切なパラメータが異なる．したがってSVMとニューラルネットワークにおいてそれぞれパラメータの調整を行い，それぞれ入力するベクトルの次元数も変えて実験を行う．以下にパラメータ調整の実験内容の詳細について述べる．

まず， SVMとニューラルネットワークに共通するパラメータとして，入力するデータの次元数について，3.2節で述べた手順でword2vecにより得られる単語ベクトルの次元数を30， 40， 50， 100， 200と変化させた．次に，SVMでは，本研究は2値分類ではなく多カテゴリ分類であるため，One-Vs-The-Rest方式を使用した．カーネル関数には，非線形のラジアル基底関数カーネル(rbfカーネル)と線形カーネル(linearカーネル)を用いた．パラメータCに関して，式(3.6)より，Cを大きくするほど，$\xi_i$が小さくなる分離超平面を決定する必要があるため，誤分類を許容できなくなる．本研究ではCを0.1， 1， 10， 100， 1000と変化させた．rbfカーネルのパラメータ$\gamma$に関して， $\gamma$が小さいほど単純な識別境界となり，大きいほど複雑な識別境界となる．カーネル関数がrbfカーネルの場合のみ， $\gamma$を0.0000001， 0.000001， 0.00001， 0.0001， 0.001と変化させた．

ニューラルネットワークでは，活性化関数はソフトマックス関数で固定した．入力層と出力層の間の中間層の数を1層，2層とした．また，各中間層のノード数を64， 128， 256， 512と変化させた．エポック数は学習を繰り返し行う回数であり，学習データに対する精度とテストデータに対する精度が共に高くなるように適切に選ぶ必要がある．本研究ではエポック数を40， 80， 160， 320と変化させた．また，本章の初めにも述べたとおり，クライエントの発言1文毎170文に対する実験と48文に対する実験を行うが，170文に対する正答率が高かったSVMのみ48文に対する実験を行う．続いて，上で述べた手法の分類精度を高めるために調整したパラメータの中で最も正答率の高かったパラメータを用いて，正答率を分類精度の指標として，本研究と会話の流れの可視化システムとの比較を行う．

また，本研究と会話の流れの可視化システムにおける分類手法に対して，正しく分類できている文と分類できていない文を調べて，比較を行う．

\subsection{実験結果}

学習アルゴリズムとして，SVMとニューラルネットワークを用いて，前節で述べた各パラメータの組み合わせごとのカテゴリ分類の正答率を求める．その中で最も正答率の高かったパラメータを用いて， 本研究における分類手法と会話の流れの可視化システムにおける分類手法との比較を行う．

まず，SVMを用いた170文に対する実験結果について述べる．SVMを用いてベクトル次元数，カーネル関数，C， $\gamma$を変えながら行った，クライエントの発言1文毎の170文に対する自動カテゴリ分類の正答率を表4.1〜4.5に示す．170文に対して最も正答率が高かったのは，ベクトル次元数30， rbfカーネル，C=1， $\gamma$ =0.00001の場合で63.5\%であった．

次元数に関して，次元数が30， 40， 50の場合は正答率に大きな差はなかったが，次元数が100， 200になると次元数が低い場合に比べて正答率が下がった．
カーネル関数に関して，どの次元数においてもrbfカーネルの方がlinearカーネルよりも高い正答率を示した．
Cに関して， $\gamma$ =0.001， 0.01と比較的大きい場合はCが最も小さい0.1の場合に正答率が高くなることが多く， $\gamma$ =0.00001， 0.0001とそれよりも小さい場合にはC=1の場合に正答率が高くなることが多かった．
$\gamma$に関して， Cの値によらず$\gamma$ =0.00001， 0.0001の場合に正答率が高くなることが多い．また、$\gamma$ =0.0000001， 0.01の場合には正答率が低くなる場合が多い． $\gamma$が0.000001以下になると，全ての次元数，Cの値において，linearカーネルの正答率と等しくなった．

次に，SVMを用いた48文に対する実験結果について述べる．
クライエントの発言1文毎の48文に対する自動カテゴリ分類の正答率を表4.6〜4.10に示す．48文に対して最も正答率が高かったのは，ベクトル次元数40， rbfカーネル，C=1， $\gamma$ =0.00001の場合で81.3\%であった． 
カーネル関数に関して，どの次元数においてもrbfカーネルの方がlinearカーネルよりも高い正答率を示した．
Cに関して，C=1000の場合は正答率が低い場合が多かった． $\gamma$ =0.001， 0.1と比較的大きい場合と，0.000001以下と比較的小さい場合はCを1000から小さくすると大半の場合に正答率が上がったが， $\gamma$ =0.00001， 0.0001の場合にはCを0.1まで小さくすると正答率が下がることが多かった．
$\gamma$に関して，Cの値によらず$\gamma$ =0.00001， 0.0001の場合に正答率が高くなることが多かった． $\gamma$が0.000001以下になると，全ての次元数，Cの値においてlinearカーネルの正答率と等しくなった．

ニューラルネットワークを用いた170文に対する実験結果について述べる．
ニューラルネットワークのベクトル次元数，中間層の数，中間層のノード数，エポック数を変えながら行った，クライエントの発言1文毎の170文に対する自動カテゴリ分類の正答率を表4.11〜4.15に示す．ニューラルネットワークでは、ベクトルの次元数，中間層の数，中間層のノード数，エポック数による正答率の顕著な傾向は現れず、SVMと比べると正答率は極端に低くなった．

次に，会話の流れの可視化システムにおける分類手法との比較についての実験結果を述べる．
本研究における分類手法と会話の流れの可視化システムにおける分類手法との170文，48文に対する分類結果をそれぞれ表4.16， 4.17に示す．
本研究の分類結果として最も正答率が高かったのは，170文に対してSVMで，カーネル関数をrbfカーネル，ベクトル次元数を30， C=1， $\gamma$ =0.00001としたものと，48文に対してSVMで，カーネル関数をrbfカーネル，ベクトル次元数を40， C=1， $\gamma$ =0.00001としたものを用いる．
ただし，会話の流れの可視化システムにおける分類手法では分類結果が未分類となっている文が170文中104文存在しており，未分類は誤ったカテゴリに分類したとみなして正答率を算出している．
結果より，170文と48文に対して共に会話の流れの可視化システムにおける分類手法よりも本研究における分類手法の方が正答率は上回っていることがわかる．

\section{考察}

4.2節の実験結果に対する考察を述べる．学習アルゴリズムであるSVMとニューラルネットワークに関して，ニューラルネットワークを用いた分類手法の正答率が低い理由として、ニューラルネットワークの学習が学習データに対して過学習を起こしていることが考える．ニューラルネットワークでは、学習データに対してはどの次元数，パラメータでも，学習データに対しては正答率が80\%を超えているが，クライエントの発言に対する正答率は平均10\% 程度である．学習データに用いたYahoo!知恵袋の質問文は，投稿者がどのカテゴリにどのような文章を投稿するかは自由である．そのため，例えば「脳がスイーツすぎませんか」，「レポートで弾性係数を調査する内容の課題が出ました．」といった3つの分類カテゴリに全く関係のない文章が多数含まれていることが過学習を起こしている原因の1つと考える．また，投稿1件全体では「家族関係に関する悩み」の内容であるが，1文毎に区切ったために，「来年，仕事を1年休みます．」という文のように「仕事」カテゴリに分類されるべき文が「愛」カテゴリの文として学習されることも過学習を起こしている原因の1つと考えられる．

それに対して，SVMの学習ではマージンを最大化するような分離超平面を決定することで，学習データに対して過学習しすぎることなく，分類カテゴリが未知のクライエントの発言に対しても高い正答率を実現できたと考える．しかしSVMでも，rbfカーネルの場合に式(3.9)において$\gamma$を大きくすると，x-x'が大きくなれば急速に指数関数項の値は0に近づく．ゆえに，そのカテゴリの教師データの近くのデータでのみ，そのカテゴリに分類されなくなる．さらにCも大きくすると誤分類を許容しなくなるため，今回Cと$\gamma$を共に大きくした場合に正答率が下がっていると考える．

次に，それぞれの分類手法で分類できている文とできていない文について述べる．例えば，「母ともよく喧嘩しますし．」，「最近お仕事でお休みを頂いているので．」といった文のように，「母」，「仕事」といったカテゴリ特有の単語が出現する文は，会話の流れの可視化システムと本研究における分類手法で共に正しく分類できている．

クライエントの配偶者についての会話の中で，ユーザーの手動修正後「愛」カテゴリに分類されている文に，「貯金とか将来のことを考えて行動していないのではないか」，「そんなことをしていて生活費がどうなるのか」，「あの一部屋に住めると思いません．」という文がある．しかし会話の流れの可視化システムにおける分類手法では，これらの文に出現する単語がシステムの辞書に登録されておらず，正しく分類できていないが，本研究における分類手法では正しく分類できている．本研究における分類手法で正しく分類できている．これは，学習データの「愛」カテゴリの文の中に「夫の収入が少なく，貯金できない．」，「私は彼と生活費を折半しています．」，「妹と母親が隣の部屋で会話をしていました．」のように，「貯金」，「生活費」，「部屋」の単語を含む文が，他のカテゴリの学習データに比べて多くなっていることが分類できた理由と考える．

さらに，本研究における分類手法で正しく分類できていなかった文の中で，特徴的な文について考察する．
クライエントの配偶者についての会話の中で，ユーザーの手動修正後「愛」カテゴリに分類されている文に，「あの人の仕事を否定したくありません．」，「貯金もしていないし，あんな仕事なので，もし事故を起こしたら・・・．」という文がある．しかし，本研究における分類手法では，「仕事」カテゴリに分類されている．これは，「仕事」のラベルをつけた学習データの文の中に「仕事」という単語を含む文が頻出しており，文中の他の単語よりも「仕事」という単語のベクトルがその文ベクトルに大きく影響しているためと考える．「あの人の仕事を否定したくありません．」といった文を正しく分類するために，文の係り受け解析を行い，「あの人」の「仕事」であることから「愛」のカテゴリと分類できる必要があると考える．

同様にクライエントの配偶者についての会話の中で，ユーザーの手動修正後「愛」カテゴリに分類されている文として，「お客さんに料理を出しすぎです．」，「将来設計なんかできません．」という文がある．しかし，本研究における分類手法では，「仕事」カテゴリに分類されている．理由の1つは，誰に関する話題であるか把握するための単語が抜けていることである．また，学習データの中に「料理」という単語が出現する回数は「愛」カテゴリでは219回であり，「仕事」カテゴリでは65回である．しかし「客」と「料理」が共に出現する文は，「簡単に注文された料理を注文してくれた客に間違わずに運べるものですか．」という文のように，アルバイトや仕事に関する文がほとんどであり，「仕事」カテゴリの学習データに多く存在する．次に，「将来設計」という単語は形態素解析を行うと，「将来」と「設計」に分かれる．「将来」という単語は「愛」カテゴリの学習データの方に多く出現するが，「設計」という単語は「仕事」カテゴリの学習データの中の設計の仕事に関する文に多く出現する．また「将来の仕事が不安です．」という文も「仕事」カテゴリの学習データに多く存在するため，「将来設計なんかできません．」という文が「仕事」カテゴリに分類されていると考える．これは形態素解析を行う際に，MeCabに予め備わっている辞書に加えて，「将来設計」のように名詞が連続した複合名詞が登録されている辞書を用いる必要があると考える．

「そういうやりすぎるところが嫌いで．」，「あの人のこだわりだと思います．」という文は「愛」カテゴリに分類されるべきであるが，前者は主語が抜けており，後者は「あの人」が誰なのか特定できず，文中の他の単語もいずれかのカテゴリの学習データに多く存在せず，共にどのカテゴリに関する文なのか判別し難い．このような文を正しく分類するために，その前の会話に遡り主語を補うことができるかの検討をする必要があると考える．
「友人が家族とのストレスを．」という文は「交友」カテゴリに分類されるべきであるが，「愛」カテゴリに頻出する「家族」という単語と「交友」カテゴリに頻出する「友人」という単語が共に出現して，「家族」を含む文の方が学習データに多く存在しているため「愛」カテゴリに分類されていると考える．

また，本研究における分類手法を用いて，48文に対する正答率は170文に対する正答率よりも高いが，80\%程度に留まっている.．この理由として，クライエントの前の発言文に遡らないとカテゴリの把握ができない文が含まれているため，正答率が低いことが考えられる．

クライエントの前の発言に遡らないとカテゴリが把握できない文や，カウンセラーからの質問に遡らないとカテゴリが把握できない返事などの短い文を正しく分類するためには，クライエントの発言1文毎の分類ではなく，カウンセラーの質問やクライエントの前の発言を含めた，会話のブロック毎の分類方法を検討する必要があると考える．

本研究では，「愛」「交友」「仕事」の3つを分類カテゴリとした．そのためこれらの3つの分類カテゴリのいずれにも当てはまらないクライエントの発言文は，ユーザーの手動修正後のカテゴリを「未分類」としている．今後は，これら未分類の文に対しても分類できる手法を検討する必要があると考える．これらの文はクライエント自身の症状に関する記述であるものが多い．アドラー心理学では，クライエントの課題のグループ分けに関して，「愛」「交友」「仕事」の3つ以外に，第4の課題とされる「自己」，第5の課題とされる「スピリチュアル」がある．これらのカテゴリを分類カテゴリに加えることで，本研究ではテストデータとしなかったクライエントの発言文に対してもカテゴリ分類を行うことを検討する必要がある．
	
%程度
