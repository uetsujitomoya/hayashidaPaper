 \begin{table}
   \caption{SVMでの次元数30の170文に対する正答率（\%）}
   \label{table:svm_30_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_30_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数40の170文に対する正答率（\%）}
   \label{table:svm_40_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_40_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数50の170文に対する正答率（\%）}
   \label{table:svm_50_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_50_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数100の170文に対する正答率（\%）}
   \label{table:svm_100_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_100_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数200の170文に対する正答率（\%）}
   \label{table:svm_200_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_200_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数30の48文に対する正答率（\%）}
   \label{table:svm_30_48}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_30_48.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{SVMでの次元数40の48文に対する正答率（\%）}
   \label{table:svm_40_48}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_40_48.png}
   \end{center}
 \end{table}

 
  \begin{table}
   \caption{SVMでの次元数50の48文に対する正答率（\%）}
   \label{table:svm_50_48}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_50_48.png}
   \end{center}
 \end{table}

 
  \begin{table}
   \caption{SVMでの次元数100の48文に対する正答率（\%）}
   \label{table:svm_100_48}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_100_48.png}
   \end{center}
 \end{table}

 
  \begin{table}
   \caption{SVMでの次元数200の48文に対する正答率（\%）}
   \label{table:svm_200_48}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_200_48.png}
   \end{center}
 \end{table}

  \begin{table}
   \caption{ニューラルネットワークでの次元数30の170文に対する正答率（\%）}
   \label{table:svm_30_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_30_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{ニューラルネットワークでの次元数40の170文に対する正答率（\%）}
   \label{table:svm_40_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_40_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{ニューラルネットワークでの次元数50の170文に対する正答率（\%）}
   \label{table:svm_50_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_50_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{ニューラルネットワークでの次元数100の170文に対する正答率（\%）}
   \label{table:svm_100_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_100_170.png}
   \end{center}
 \end{table}
 
 

 \begin{table}
   \caption{ニューラルネットワークでの次元数200の170文に対する正答率（\%）}
   \label{table:svm_200_170}
   \begin{center}
     \includegraphics[width=\linewidth]{svm_200_170.png}
   \end{center}
 \end{table}

 \begin{table}
   \caption{170文に対する分類手法の比較}
   \label{table:170_compare}
   \begin{center}
     \includegraphics[width=\linewidth]{170_compare.png}
   \end{center}
 \end{table}
 

 \begin{table}
   \caption{48文に対する分類手法の比較}
   \label{table:48_compare}
   \begin{center}
     \includegraphics[width=\linewidth]{48_compare.png}
   \end{center}
 \end{table}
本章では，本研究における分類手法の分類精度を高めるための実験，会話の流れの可視化システムにおける分類手法との比較を行う．さらに，実験結果に対する考察を述べる．
そして本研究における分類手法の問題点を述べる．

\section{実験概要}

本研究で機械学習を行うために使用したライブラリについて述べる．SVMによる学習を行うために，オープンソースの機械学習ライブラリであるscikit-learnを使用する．次にニューラルネットワークによる学習を行うために，Googleが開発しオープンソースとして公開されているTensorflowを使用する．共に使用したプログラム言語はPythonである．
次に本研究の実験で使用したテキストデータについて以下に述べる．
word2vecの学習に用いたコーパスは，Yahoo!知恵袋の「恋愛相談」，「友人関係の悩み」，「家族関係の悩み」，「職場の悩み」４カテゴリの，各カテゴリ6000件ずつ，質問24000件，質問に対するベストアンサー24000件の計48000件である．
機械学習の教師データに用いたテキストデータは， Yahoo!知恵袋の，「家族関係の悩み」，「友人関係の悩み」，「職場の悩み」カテゴリの質問文を1文毎に区切った，各カテゴリ6000文ずつ，計18000文である．
機械学習のテストデータに用いたテキストデータは，クライエントの発言のうち，熟練カウンセラーの手動修正後「愛」「交友」「仕事」いずれかのカテゴリに分類されていた170文である．
word2vec学習に用いたテキストデータの1件とは，投稿者1人の投稿文章である．word2vecに用いたコーパスは単語数6298390，語彙数18100，サイズ37．4MBである．
教師データに関して，質問文のみを用いるのは，本研究における分類対象はクライエントの発言内容であり，相談することを目的としてYahoo!知恵袋に投稿した投稿者の質問文が内容的に比較的類似していると考えたためである．そして質問文を1文毎に区切り，3.3節で述べた手順に従って，1文毎に文ベクトルを作成する．ここで1文とは句点やクエスチョンマークで区切られた単位のことである．「家族関係の悩み」カテゴリから取得した質問文1文毎の文ベクトルに「愛」のラベル，「友人関係の悩み」カテゴリの質問文1文毎の文ベクトルに「交友」ラベル，「職場の悩み」カテゴリの質問文1文毎の文ベクトルに「仕事」ラベルをそれぞれ付けて，それを教師データとする．
テストデータに関して，クライエントの発言1文毎のうち，ユーザーの手動修正後「愛」「交友」「仕事」いずれかのカテゴリに分類されていた170文をテストデータに用いる．クライエントの発言170文に対して3.3節で述べた手順に従い文ベクトルを算出し，テストデータとした．第1章でも述べたように，会話の流れの可視化システムにおけるクライエントの発言の分類結果を，熟練カウンセラーが確認を行い，誤った分類箇所を手動修正している．その手動修正後の分類カテゴリをテストデータの正解カテゴリとする．
しかし，クライエントの発言1文毎の170文の中には，カウンセラーからの質問に対する単なる返事などといった，その1文だけをカテゴリ分類するのが難しいと考えられる文も含まれている．そこで，

1．「そのことで夜眠れなくて・・・」のように，「そのこと」が何のことなのかを把握する為には前の発言文に遡らなければならない文

2．「不安です．」のように，カウンセラーからの質問に対する返事などの短い文

を170文から除外した48文に対しての実験も同様に行う．
以下の実験を行う際に，分類精度を評価する指標として本研究では正答率を用いる．正答率とは，全てのテストデータに対して，正しいカテゴリを出力した割合であり，テストデータのうち正解カテゴリと同じ出力をした数をT，正解カテゴリと異なる出力した数をF，正答率(\%)をAccuracyとすると，
\begin{equation}
  Accuracy=\frac{T}{T+F}×100
\end{equation}
と表すことができる．
これらのテキストデータ，評価指標を用いて以下に述べる実験を行う．

\section{実験結果}

\subsection{実験内容}

初めに，SVMとニューラルネットワークそれぞれについて，本研究における分類手法の精度を高めるために，パラメータを調整する実験を行う．3.4節で述べたように，SVMではカーネル関数とパラメータCおよび$\gamma$の選択によって分離超平面がそれぞれ異なり分類精度も大きく異なる．ニューラルネットワークでも同様に扱うデータにより適切なパラメータが異なる．したがってSVMとニューラルネットワークにおいてそれぞれパラメータの調整を行い，それぞれ入力するベクトルの次元数も変えて実験を行う．以下にパラメータ調整のための実験内容の詳細を述べる．まず， SVMとニューラルネットワークに共通するパラメータとして，入力するデータの次元数である，3.2節で述べた手順でword2vecにより得る単語ベクトルの次元数を30， 40， 50， 100， 200と変化させた．次に，SVMにおいては，3.4節で述べたが，本研究は2値分類ではなく多カテゴリ分類であり，本研究ではOne-Vs-The-Rest方式を使用した．カーネル関数には，非線形のラジアル基底関数カーネル(rbfカーネル)と線形カーネル(linearカーネル)を用いた．パラメータCに関して，式(3.6)より，Cを大きくするほど，$\xi_i$が小さくなるような分離超平面を決定しなければならなく，つまり誤分類を許容できなくなる．本研究ではCを0.1， 1， 10， 100， 1000と変化させた．rbfカーネルのパラメータ$\gamma$に関して， $\gamma$が小さいほど単純な識別境界となり，大きいほど複雑な識別境界となる．カーネル関数がrbfカーネルの場合のみ， $\gamma$を0.0000001， 0.000001， 0.00001， 0.0001， 0.001と変化させた．ニューラルネットワークにおいては，	活性化関数はソフトマックス関数で固定した．入力層と出力層の間の中間層の数を1層，2層とした．また，各中間層のノード数を64， 128， 256， 512と変化させた．エポック数は学習を繰り返し行う回数であり，学習データに対する精度とテストデータに対する精度が共に高くなるように適切に選ぶ必要がある．本研究ではエポック数を40， 80， 160， 320と変化させた．また，本章の初めにも述べたとおり，クライエントの発言1文毎170文に対する実験と48文に対する実験を述べるが，170文に対する正答率がより良かったSVMのみ48文に対する実験を行う．続いて，上で述べた分類手法の精度を高めるために調整したパラメータの中で最も正答率の高かったパラメータを用いて，正答率を分類精度の指標として，本研究と会話の流れの可視化システムとの分類手法の比較を行う．

また，本研究と会話の流れの可視化システムにおける分類手法それぞれに対して，正しく分類できている文と分類できていない文を調べて比較を行う．

\subsection{実験結果}

学習アルゴリズムとして，SVMとニューラルネットワークを用いたそれぞれで，前節で述べた各パラメータの組み合わせごとのカテゴリ分類の正答率を述べ，その中で最も正答率の高かったパラメータを用いて， 本研究における分類手法と会話の流れの可視化システムにおける分類手法との比較を行う．
SVMを用いて，170文に対する実験結果を述べる．
SVMを用いてベクトル次元数，カーネル関数，C， $\gamma$を変えながら行った，クライエントの発言1文毎の170文に対する自動カテゴリ分類の正答率を表4.1〜4.5に示す．170文に対して最も正答率が高かったのは，ベクトル次元数30， rbfカーネル，C=1， $\gamma$ =0.00001の場合で63.5\%であった．
次元数に関して，次元数が30， 40， 50の場合は正答率にそれほど大きな差はなかったが，次元数が100， 200になると次元数が低い場合に比べて正答率が下がった．
カーネル関数に関して，どの次元数においてもrbfカーネルの方がlinearカーネルよりも高い正答率を示した．
Cに関して， $\gamma$ =0.001， 0.01と比較的大きい場合はCが最も小さい0.1の場合に正答率が高くなることが多く， $\gamma$ =0.00001， 0.0001とそれよりも小さい場合にはC=1の場合に正答率が高くなることが多かった．
$\gamma$に関して， Cの値によらず$\gamma$ =0.00001， 0.0001の場合に正答率が高いことが多い．また、$\gamma$ =0.0000001， 0.01の場合には正答率が低い場合が多い． $\gamma$が0.000001以下になると，全ての次元数，Cの値において，linearカーネルの正答率と等しくなった．
次に，SVMを用いて，48文に対する実験結果を述べる．
クライエントの発言1文毎の48文に対する自動カテゴリ分類の正答率を表4.6〜4.10に示す．48文に対して最も正答率が高かったのは，ベクトル次元数40， rbfカーネル，C=1， $\gamma$ =0.00001の場合で81.3\%であった． 
カーネル関数に関して，どの次元数においてもrbfカーネルの方がlinearカーネルよりも高い正答率を示した．
Cに関して，C=1000の場合は正答率が低いことが多かった． $\gamma$ =0.001， 0.1と比較的大きい場合と，0.000001以下と比較的小さい場合はCを1000から小さくしていくとほとんどの場合に正答率が上がっていったが， $\gamma$ =0.00001， 0.0001の場合にはCを0.1まで小さくすると正答率が下がることが多かった．
$\gamma$に関して，Cの値によらず$\gamma$ =0.00001， 0.0001の場合に正答率が高くなることが多かった． $\gamma$が0.000001以下になると，全ての次元数，Cの値においてlinearカーネルの正答率と等しくなった．
ニューラルネットワークを用いて，170文に対する実験結果を述べる．
ニューラルネットワークを用いてベクトル次元数，中間層の数，中間層のノード数，エポック数を変えながら行った，クライエントの発言1文毎の170文に対する自動カテゴリ分類の正答率を表4.11〜4.15に示す．ニューラルネットワークでは、ベクトルの次元数，中間層の数，中間層のノード数，エポック数による正答率の顕著な傾向は現れず、SVMと比べると正答率は極端に低くなった．
次に，会話の流れの可視化システムにおける分類手法との比較についての実験結果を述べる．
本研究における分類手法と会話の流れの可視化システムにおける分類手法との170文，48文に対する分類結果をそれぞれ表4.16， 4.17に示す．
本研究における分類手法には，170文に対して最も正答率の高かった，SVMで，カーネル関数をrbfカーネル，ベクトル次元数を30， C=1， $\gamma$ =0.00001としたものと，48文に対して最も正答率の高かった，SVMで，カーネル関数をrbfカーネル，ベクトル次元数を40， C=1， $\gamma$ =0.00001としたものを用いる．
ただし，会話の流れの可視化システムにおける分類手法では分類結果が未分類となっている文が170文中104文存在しているが，未分類は誤ったカテゴリに分類したとみなして正答率を算出している．
170文と48文に対して共に会話の流れの可視化システムにおける分類手法よりも本研究における分類手法の方が正答率は上回っている．

\section{考察}

4.2節の実験結果に対する考察を述べる．

学習アルゴリズムであるSVMとニューラルネットワークに関して，ニューラルネットワークを用いた分類手法の正答率が低い理由としては、ニューラルネットワークの学習が学習データに対して過学習を起こしていると考える．ニューラルネットワークにおいてどの次元数，パラメータにおいても，学習データに対しては正答率が80\%を超えているが，クライエントの発言に対しての正答率は平均して10\%ほどである．学習データに用いたYahoo!知恵袋の質問文は，投稿者がどのカテゴリにどのような文章を投稿するかは自由であり，「脳がスイーツすぎませんか」，「レポートで弾性係数を調査する内容の課題が出ました．」といった3つの分類カテゴリに全く関係のない文章が含まれていることが過学習を起こしている原因の1つであると考える．また，投稿1件全体では「家族関係に関する悩み」の内容のものであるが，1文毎に区切ったために，「来年，仕事を1年休みます．」という文のように「仕事」カテゴリに分類されるべきであろう文が「愛」カテゴリの文として学習されてしまうことも過学習を起こしている原因の1つであると考える．

それに対してSVMの学習ではマージンを最大化するような分離超平面を決定することで，学習データに対して過学習しすぎることなく，分類カテゴリが未知のクライエントの発言に対しても高い正答率を実現できたと考える．

しかしSVMでも、rbfカーネルの場合に式(9)において$\gamma$を大きくすると，x-x'が大きくなれば急速に指数関数項の値は0に近づく．すなわちそのカテゴリの教師データの近くのデータしかそのカテゴリに分類されなくなる．さらにCも大きくすると誤分類を許容しなくなるため，今回Cと$\gamma$を共に大きくした場合に正答率が下がっていると考える．

次にそれぞれの分類手法で分類できている文とできていない文について述べる．「母ともよく喧嘩しますし．」，「最近お仕事でお休みを頂いているので．」という文のように，「母」，「仕事」といったカテゴリ特有の単語が出現する文は，会話の流れの可視化システムと本研究における分類手法で共に正しく分類できている．

クライエントの配偶者についての会話の中で，ユーザーの手動修正後「愛」カテゴリに分類されている文に，「貯金とか将来のことを考えて行動していないのではないか」，「そんなことをしていて生活費がどうなるのか」，「あの一部屋に住めると思いません．」という文がある．しかし会話の流れの可視化システムにおける分類手法では，これらの文に出現する単語がシステムの辞書には登録されておらず，正しく分類できていないが，本研究における分類手法では正しく分類できている．本研究における分類手法で正しく分類できているのは，学習データの「愛」カテゴリの文の中に「夫の収入が少なく，貯金できない．」，「私は彼と生活費を折半しています．」，「妹と母親が隣の部屋で会話をしていました．」のように，「貯金」，「生活費」，「部屋」の単語を含む文が，他のカテゴリの学習データに比べて多いことが理由であると考える．

本研究における分類手法で正しく分類できていなかった文の中で特徴的な文について述べる．
クライエントの配偶者についての会話の中で，ユーザーの手動修正後「愛」カテゴリに分類されている文に，「あの人の仕事を否定したくありません．」，「貯金もしていないし，あんな仕事なので，もし事故を起こしたら・・・．」という文がある．しかし，本研究における分類手法では，「仕事」カテゴリに分類されている．これは，「仕事」のラベルをつけた学習データの文の中に「仕事」という単語を含む文が頻出しており，文中の他の単語よりも「仕事」という単語のベクトルがその文ベクトルに大きく影響しているためと考える．「あの人の仕事を否定したくありません．」というような文を正しく分類するために，文の係り受け解析を行い，「あの人」の「仕事」であることから「愛」のカテゴリであると分類できるようにする必要があると考える．

同様にクライエントの配偶者についての会話の中で，ユーザーの手動修正後「愛」カテゴリに分類されている文として，「お客さんに料理を出しすぎです．」，「将来設計なんかできません．」という文がある．しかし，本研究における分類手法では，「仕事」カテゴリに分類されている．理由の1つは，誰に関する話題であるか把握するための単語が抜けていることである．また，学習データの中に「料理」という単語が出現する回数は「愛」カテゴリでは219回であり，「仕事」カテゴリでは65回である．しかし「客」と「料理」が共に出現する文は，「簡単に注文された料理を注文してくれた客に間違わずに運べるものですか．」という文のように，アルバイトや仕事に関する文がほとんどであり，「仕事」カテゴリの学習データに多く存在する．次に，「将来設計」という単語は形態素解析を行うと，「将来」と「設計」に分かれてしまう．「将来」という単語は「愛」カテゴリの学習データの方に多く出現するが，「設計」という単語は「仕事」カテゴリの学習データの中の設計の仕事に関する文に多く出現し，また「将来の仕事が不安です．」という文も「仕事」カテゴリの学習データに多く存在するため，「将来設計なんかできません．」という文が「仕事」カテゴリに分類されていると考える．形態素解析を行う際に，MeCabに予め備わっている辞書に加えて，「将来設計」のように名詞が連続した複合名詞が登録されている辞書を用いる必要があると考える．

「そういうやりすぎるところが嫌いで．」，「あの人のこだわりだと思います．」という文は「愛」カテゴリに分類されるべきであるが，前者は主語が抜けており，後者は「あの人」が誰なのか特定できず，文中の他の単語もいずれかのカテゴリの学習データに多く存在せず，共にどのカテゴリに関する文なのか判別し難い．このような文を正しく分類するために，その前の会話に遡り主語を補うことができるかの検討をする必要があると考える．
「友人が家族とのストレスを．」という文は「交友」カテゴリに分類されるべきであるが，「愛」カテゴリに頻出する「家族」という単語と「交友」カテゴリに頻出する「友人」という単語が共に出現して，「家族」を含む文の方が学習データに多く存在しているため「愛」カテゴリに分類されていると考える．
また，本研究における分類手法を用いての，48文に対する正答率は170文に対する正答率よりも高いが，80\%程度に留まっている理由として，クライエントの前の発言文に遡らないとカテゴリの把握ができない文に対しては正答率が低いためと考える．

クライエントの前の発言に遡らないとカテゴリが把握できない文や，カウンセラーからの質問に遡らないとカテゴリが把握できない返事などの短い文を正しく分類するために，今後クライエントの発言1文毎の分類ではなく，カウンセラーの質問やクライエントの前の発言を含めた，会話のブロック毎の分類を検討する必要があると考える．

分類カテゴリに関して，本研究では「愛」「交友」「仕事」の3つを分類カテゴリとした．そのためこれらの3つの分類カテゴリのいずれにも当てはまらないクライエントの発言文は，ユーザーの手動修正後のカテゴリを「未分類」としている．今後これらの文に対しても分類を行う必要があると考える．これらの文はクライエント自身の症状に関する記述であるものが多い．そこで，アドラー心理学において，クライエントの課題のグループ分けに関して，「愛」「交友」「仕事」の3つ以外に，第4の課題とされる「自己」，第5の課題とされる「スピリチュアル」がある．これらのカテゴリを分類カテゴリに加えることで，本研究ではテストデータとしなかったクライエントの発言文に対してもカテゴリ分類を行うことを検討する必要がある．
	
