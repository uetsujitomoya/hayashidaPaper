%本章では，関連する先行研究と本研究との位置づけについて述べる．

%\section{テキストデータ分析}



%テキストデータ分析はテキスト要約や単語同士の関係の分析など，様々な目的で行われている．たとえばKH Coder\cite{kh1}は，テキスト文章型のデータを統計分析するためのフリーのソフトウェアである．アンケートの自由記述・インタビュー記録・新聞記事など，さまざまな社会調査データを分析するため，立命館大学の樋口が開発したものである．杉浦ら\cite{kango}は成人看護学概論の成長報告書にKH Coderの単語共起ネットワーク図機能を適用することで，成人看護学概論にプロジェクト学習を採用した効果を明らかにした．


%%以下に，KH Coderの主な可視化システムについて紹介する．




本章では,本研究との関連研究を示し,その位置づけについて述べる.

テキスト分類は,スパムメールの自動振り分けやニュース記事の自動分類など様々な目的で行われている.近年,機械学習を用いたテキスト分類に関する研究が盛んに行われ,その中でも教師付き学習によるテキスト分類に関する研究が数多く行われている.

平ら\cite{110002934804}は機械学習によるテキスト分類問題に対して,出現頻度の小さい単語まで考慮した学習を行わなければ分類精度が落ちることを述べ,高次元の単語ベクトルを用いるためにSVMを用いた学習を行うことで,ニュース記事の分類において高い分類精度を実現した.この研究ではニュース記事の各文書の中から名詞を抽出し,Bag-of-wordsモデルによって文書をベクトル化している.ここでBag-of-wordsとは文書中の単語の並びなどは考えず,文書に単語が含まれているかどうかのみを考えるモデルである.

従来ではニュース記事のように,ある程度文章が長く単語数や単語の種類も多い文書のベクトル化の際にはBag-of-wordsモデルがよく使われてきたが,本研究での分類対象はクライエントの発言1文毎であり,文の長さが短く単語数も少ないものが多い.そのため名詞を抽出しBag-of-wordsモデルを用いて各文をベクトル化しても,その文の特徴が表れにくいと考えられる.

短い文の分類では,Sriramら\cite{ShortText}はTwitterのTweet内容を「ニュース」や「イベント」など5つの目的別に自動カテゴリ分類する手法を提案した.この研究ではBag-of-wordsによる素性に加えて,Tweetの中に略語やスラングが使われているか,時間や場所についての記載があるか,など8つの特徴を基にした素性も加えることで,Bag-of-wordsのみによる素性を用いるよりも高い精度でTweetの自動カテゴリ分類を行った.Sriramらの研究での分類カテゴリは,例えば「イベント」であれば時間や場所についての記載が多い,などのカテゴリ毎のTweetの特徴が顕著であるが,本研究での分類カテゴリである「愛」「仕事」「交友」にはそのような顕著な特徴は存在しない.

また,Bag-of-wordsモデルのデメリットとして,「友達」と「友だち」などの表記ゆれや,「父親」と「父さん」のような同義語を,全く別の単語として捉えるといった点が挙げられる.さらに,文書のベクトル次元数が学習する全コーパス中の語彙数と等しくなるため,本研究でも学習コーパスの語彙数は約2万でありベクトル次元数も2万にも及ぶ.そのためニューラルネットワークを用いて学習を行うと,計算時間が膨大になるという問題があるBag-of-wordsによるベクトルを次元圧縮したものを用いる手法も考えられるが,永田ら\cite{pylearn}によって次元圧縮により分類精度が下がったことが示されている.

Mikolovら\cite{DBLP:journals/corr/abs-1301-3781}は単語の分散表現を学習して単語のベクトル化を行うword2vecを提案した.word2vecでは数百次元程度の密なベクトルで単語を高い精度で表現することが可能であり,現在もその用途について様々な研究が行われている.

word2vecにより得られた単語の分散表現を用いて,単語間の意味的な類似度を求めることが可能であり,日本語の研究として単語の意味を取り扱う研究が行われている.野沢ら\cite{110009950250}は,大量のレシピデータから食材と調理法を抽出し,word2vecで学習させ,word2vecで得られた単語ベクトルから各単語に類似する単語を算出し代替食材を発見する手法を提案した.また,菅原ら\cite{cancellation}は単語の分散表現を用いて多義語の語義曖昧性を解消する手法を提案した.語義曖昧性というのは,例えば”cool”という単語は「涼しい」や「かっこいい」など複数の語義を持つために,文脈により語義が異なることを言う.そこでword2vecにより得た単語の分散表現を用いて,文書中における多義語の最もふさわしい語義を選ぶことを目的としている.

しかし,word2vecにより得た単語ベクトルを基に文章ベクトルを作成し,機械学習による文章分類に応用している日本語の研究事例は少ない.

日本語以外を取り扱う,word2vecにより得た単語ベクトルを基にした文書分類では,Xingら\cite{dcdwv}は,word2vecで得た単語ベクトルと,LDAモデルを用いた単語ベクトルを用いてそれぞれで文書ベクトルを作成した後に機械学習を行い,中国語のニュース記事の自動分類精度を比較した.機械学習アルゴリズムとしてはナイーブベイズ,k近傍法,SVMを用い,その結果word2vecで得た単語ベクトルを基に文書ベクトルを作成しSVMで機械学習を行う分類手法が最も精度が高かったことを示した.

また加藤ら\cite{word2vec}は商品に対するレビューデータと評点に対し,word2vecと深層学習を用いて評判分析を行い,1-of-Kベクトルを用いたロジスティック回帰の性能とほぼ同程度であることを示した.しかし先に述べたように,本研究ではクライエントの発言１文毎を分類対象としているため,1-of-Kベクトルを用いての分類は不適当と考える.

本研究における手法として,word2vecにより単語の分散表現を学習して得た単語ベクトルを基に,知恵袋の悩み相談に関する質問文を１文毎にベクトル化し,SVMとニューラルネットワークによる機械学習を行い,クライエントの発言1文毎に対する自動カテゴリ分類を行った.その後,本研究における分類手法と会話の流れ可視化システムにおける分類手法との比較を行った.

